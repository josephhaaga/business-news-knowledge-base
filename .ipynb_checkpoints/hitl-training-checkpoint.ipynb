{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import spacy\n",
    "from spacy.util import minibatch, compounding\n",
    "from spacy.kb import KnowledgeBase\n",
    "\n",
    "from src.utils import LanguageService"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "vocab = nlp.vocab\n",
    "kb = KnowledgeBase(vocab=vocab, entity_vector_length=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"https://www.cnbc.com/2020/09/22/palantir-says-it-expects-42percent-revenue-growth-this-year-to-1point06-billion.html\"\n",
    "ls = LanguageService()\n",
    "doc = ls.download_article(URL)\n",
    "sentences = [x.text.replace(\"\\n\", \"\") for x in doc.sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENTITIES = [\n",
    "    {\"name\": \"Palantir\", \"label\": \"ORG\", \"KB_QID\": \"Q2047336\"},\n",
    "    {\"name\": \"Alex Karp\", \"label\": \"PERSON\", \"KB_QID\": \"Q19560940\"},\n",
    "    {\"name\": \"Elysee Palace\", \"label\": \"FAC\", \"KB_QID\": \"Q188190\"},\n",
    "    {\"name\": \"Paris\", \"label\": \"GPE\", \"KB_QID\": \"Q90\"}\n",
    "]\n",
    "\n",
    "\n",
    "def find_all_mention_spans(text, substring):\n",
    "    import re\n",
    "    return [(m.start(), m.end()) for m in re.finditer(substring, text)]\n",
    "\n",
    "\n",
    "def generate_training_data(entities, sentences):\n",
    "    TRAIN_DATA = []\n",
    "\n",
    "    for sentence in sentences:\n",
    "        entity_mentions_in_sentence = []\n",
    "        for entity in ENTITIES:\n",
    "            entity_mentions_in_sentence += [\n",
    "                (x[0], x[1], entity['label']) for x in find_all_mention_spans(sentence, entity['name'])\n",
    "            ]\n",
    "        if len(entity_mentions_in_sentence) > 0:\n",
    "            TRAIN_DATA += [(\n",
    "                sentence,\n",
    "                {\"entities\": entity_mentions_in_sentence}\n",
    "            )]\n",
    "\n",
    "    return TRAIN_DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA = generate_training_data(ENTITIES, sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_vector_from_doc(word, doc):\n",
    "    spans = find_all_mention_spans(doc.text, word)\n",
    "    if len(spans) == 0:\n",
    "        raise RuntimeError(f\"{word} not found in document\")\n",
    "    start, end = spans[0]\n",
    "    return doc.char_span(start, end).vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-80-41fa2db574fa>:4: UserWarning: [W018] Entity 'Q2047336' already exists in the Knowledge Base - ignoring the duplicate entry.\n",
      "  kb.add_entity(\n"
     ]
    }
   ],
   "source": [
    "for entity in ENTITIES:\n",
    "    name = entity['name']\n",
    "    vector = get_word_vector_from_doc(name, doc)\n",
    "    kb.add_entity(\n",
    "        entity=entity['KB_QID'],\n",
    "        freq=doc.text.count(name),\n",
    "        entity_vector=vector\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 35.909622068924364}\n",
      "Losses {'ner': 26.541565783525584}\n",
      "Losses {'ner': 28.069616295517562}\n",
      "Losses {'ner': 18.780868357628048}\n",
      "Losses {'ner': 5.333915633486223}\n",
      "Losses {'ner': 9.809165925092229}\n",
      "Losses {'ner': 3.1300867514058615}\n",
      "Losses {'ner': 4.783773336845864}\n",
      "Losses {'ner': 2.987163951148775}\n",
      "Losses {'ner': 2.008933871972911}\n",
      "Entities [('Palantir', 'ORG')]\n",
      "Tokens [('Palantir', 'ORG', 3), (\"'s\", '', 2), ('update', '', 2), ('shows', '', 2), ('that', '', 2), ('revenue', '', 2), ('growth', '', 2), ('is', '', 2), ('accelerating', '', 2), ('from', '', 2), ('2019', '', 2), (',', '', 2), ('when', '', 2), ('the', '', 2), ('company', '', 2), ('reported', '', 2), ('a', '', 2), ('25', '', 2), ('%', '', 2), ('increase', '', 2), ('to', '', 2), ('$', '', 2), ('742.6', '', 2), ('million', '', 2), ('.', '', 2)]\n",
      "\n",
      "Entities [('Palantir', 'ORG')]\n",
      "Tokens [(':', '', 2), ('Palantir', 'ORG', 3), ('prepares', '', 2), ('to', '', 2), ('go', '', 2), ('public', '', 2)]\n",
      "\n",
      "Entities [('Palantir', 'ORG')]\n",
      "Tokens [('Excluding', '', 2), ('options', '', 2), ('and', '', 2), ('other', '', 2), ('unvested', '', 2), ('stock', '', 2), (',', '', 2), ('Palantir', 'ORG', 3), ('reported', '', 2), ('a', '', 2), ('fully', '', 2), ('-', '', 2), ('diluted', '', 2), ('share', '', 2), ('count', '', 2), ('of', '', 2), ('1.92', '', 2), ('billion', '', 2), ('.', '', 2)]\n",
      "\n",
      "Entities [('Palantir', 'ORG')]\n",
      "Tokens [('Palantir', 'ORG', 3), ('said', '', 2), ('in', '', 2), ('a', '', 2), ('filing', '', 2), ('ahead', '', 2), ('of', '', 2), ('next', '', 2), ('week', '', 2), (\"'s\", '', 2), ('public', '', 2), ('market', '', 2), ('listing', '', 2), ('that', '', 2), ('it', '', 2), ('expects', '', 2), ('to', '', 2), ('record', '', 2), ('growth', '', 2), ('this', '', 2), ('year', '', 2), ('of', '', 2), ('42', '', 2), ('%', '', 2), (',', '', 2), ('to', '', 2), ('close', '', 2), ('2020', '', 2), ('with', '', 2), ('$', '', 2), ('1.06', '', 2), ('billion', '', 2), ('in', '', 2), ('revenue', '', 2), ('.', '', 2)]\n",
      "\n",
      "Entities [('Palantir', 'ORG')]\n",
      "Tokens [('Palantir', 'ORG', 3), ('is', '', 2), ('taking', '', 2), ('an', '', 2), ('unconventional', '', 2), ('approach', '', 2), ('to', '', 2), ('the', '', 2), ('public', '', 2), ('market', '', 2), ('in', '', 2), ('pursuing', '', 2), ('a', '', 2), ('direct', '', 2), ('listing', '', 2), ('rather', '', 2), ('than', '', 2), ('an', '', 2), ('IPO', '', 2), ('.', '', 2)]\n",
      "\n",
      "Entities [('Palantir', 'ORG')]\n",
      "Tokens [('As', '', 2), ('investors', '', 2), ('analyze', '', 2), ('Palantir', 'ORG', 3), (\"'s\", '', 2), ('business', '', 2), ('model', '', 2), (',', '', 2), ('one', '', 2), ('key', '', 2), ('question', '', 2), ('is', '', 2), ('whether', '', 2), ('the', '', 2), ('company', '', 2), ('can', '', 2), ('dramatically', '', 2), ('expand', '', 2), ('its', '', 2), ('customer', '', 2), ('base', '', 2), ('beyond', '', 2), ('the', '', 2), ('current', '', 2), ('number', '', 2), ('of', '', 2), ('125', '', 2), ('by', '', 2), ('relying', '', 2), ('more', '', 2), ('on', '', 2), ('easy', '', 2), ('-', '', 2), ('to', '', 2), ('-', '', 2), ('use', '', 2), ('software', '', 2), ('and', '', 2), ('less', '', 2), ('on', '', 2), ('hefty', '', 2), ('deployments', '', 2), ('.', '', 2)]\n",
      "\n",
      "Entities [('Palantir', 'ORG'), ('Alex Karp', 'PERSON'), ('the Elysee Palace', 'FAC'), ('Paris', 'GPE')]\n",
      "Tokens [('CEO', '', 2), ('of', '', 2), ('Palantir', 'ORG', 3), ('Alex', 'PERSON', 3), ('Karp', 'PERSON', 1), ('leaves', '', 2), ('the', 'FAC', 3), ('Elysee', 'FAC', 1), ('Palace', 'FAC', 1), ('in', '', 2), ('Paris', 'GPE', 3), (',', '', 2), ('on', '', 2), ('May', '', 2), ('23', '', 2), (',', '', 2), ('2018', '', 2), ('after', '', 2), ('the', '', 2), ('\"', '', 2), ('Tech', '', 2), ('for', '', 2), ('Good', '', 2), ('\"', '', 2), ('summit', '', 2), ('.', '', 2)]\n",
      "\n",
      "Entities [('Palantir', 'ORG')]\n",
      "Tokens [('For', '', 2), ('2021', '', 2), (',', '', 2), ('Palantir', 'ORG', 3), ('said', '', 2), ('it', '', 2), ('expects', '', 2), ('revenue', '', 2), ('growth', '', 2), ('of', '', 2), ('greater', '', 2), ('than', '', 2), ('30', '', 2), ('%', '', 2), ('.', '', 2)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "other_pipes = [pipe for pipe in nlp.pipe_names if pipe != \"ner\"]\n",
    "n_iter = 10\n",
    "\n",
    "with nlp.disable_pipes(*other_pipes):\n",
    "    for itn in range(n_iter):\n",
    "        random.shuffle(TRAIN_DATA)\n",
    "        losses = {}\n",
    "        batches = minibatch(TRAIN_DATA, size=compounding(4.0, 32.0, 1.001))\n",
    "        for batch in batches:\n",
    "            texts, annotations = zip(*batch)\n",
    "            nlp.update(texts, annotations, drop=0.35, losses=losses)\n",
    "        print(\"Losses\", losses)\n",
    "\n",
    "# test the trained model\n",
    "for text, _ in TRAIN_DATA:\n",
    "    doc = nlp(text)\n",
    "    print(\"Entities\", [(ent.text, ent.label_) for ent in doc.ents])\n",
    "    print(\"Tokens\", [(t.text, t.ent_type_, t.ent_iob) for t in doc])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2 = nlp(\" \".join(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Palantir,\n",
       " Alex Karp,\n",
       " the Elysee Palace,\n",
       " Paris,\n",
       " Palantir,\n",
       " Palantir,\n",
       " Palantir,\n",
       " Palantir,\n",
       " Palantir,\n",
       " Palantir,\n",
       " 9.17,\n",
       " Palantir)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2.ents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eventually"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Run article thru model, noting extracted entities\n",
    "    - for those that don't resolve to a KnowledgeBase entity, ask user to find it on Wikidata\n",
    "\n",
    "2. Add new entities to KnowledgeBase\n",
    "\n",
    "3. Retrain model\n",
    "\n",
    "4. Re-run article thru model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.span.Span"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Run article thru model, noting extracted entities\n",
    "doc = nlp(article)\n",
    "\n",
    "#     - for those that don't resolve to a KnowledgeBase entity, ask user to find it on Wikidata\n",
    "unrecognized_entities = []\n",
    "for entity in doc.ents:\n",
    "    if entity.kb_id_ == '':\n",
    "        qid = input(f\"Wikidata QID for {entity.text} (press Enter to skip): \")\n",
    "        if qid != '':\n",
    "            determined_label = input(f\"NER annotation tag for {entity.text}: \"\n",
    "            # TODO: determine from Wikidata SPARQL query on the QID doc\n",
    "            unrecognized_entities += [{\"name\": entity.text, \"label\": determined_label, \"KB_QID\": qid}]\n",
    "\n",
    "\n",
    "# 2. Add new entities to KnowledgeBase\n",
    "for entity in unrecognized_entities:\n",
    "    name = entity['name']\n",
    "    vector = get_word_vector_from_doc(name, doc)\n",
    "    kb.add_entity(\n",
    "        entity=entity['KB_QID'],\n",
    "        freq=doc.text.count(name),\n",
    "        entity_vector=vector\n",
    "    )\n",
    "\n",
    "\n",
    "# 3. Retrain model\n",
    "other_pipes = [pipe for pipe in nlp.pipe_names if pipe != \"ner\"]\n",
    "N_ITER = 10\n",
    "\n",
    "with nlp.disable_pipes(*other_pipes):\n",
    "    for itn in range(n_iter):\n",
    "        random.shuffle(TRAIN_DATA)\n",
    "        losses = {}\n",
    "        batches = minibatch(TRAIN_DATA, size=compounding(4.0, 32.0, 1.001))\n",
    "        for batch in batches:\n",
    "            texts, annotations = zip(*batch)\n",
    "            nlp.update(texts, annotations, drop=0.35, losses=losses)\n",
    "        print(\"Losses\", losses)\n",
    "\n",
    "\n",
    "# 4. Re-run article thru model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.ents[0].kb_id_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
